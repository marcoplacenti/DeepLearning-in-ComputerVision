{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db4f50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import PIL.Image as Image\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c862fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"The code will run on GPU.\")\n",
    "else:\n",
    "    print(\"The code will run on CPU. Go to Edit->Notebook Settings and choose GPU as the hardware accelerator\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b36a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hotdog_NotHotdog(torch.utils.data.Dataset):\n",
    "    def __init__(self, train, transform, data_path='/dtu/datasets1/02514/hotdog_nothotdog'):\n",
    "        'Initialization'\n",
    "        self.transform = transform\n",
    "        data_path = os.path.join(data_path, 'train' if train else 'test')\n",
    "        image_classes = [os.path.split(d)[1] for d in glob.glob(data_path +'/*') if os.path.isdir(d)]\n",
    "        image_classes.sort()\n",
    "        self.name_to_label = {c: id for id, c in enumerate(image_classes)}\n",
    "        self.image_paths = glob.glob(data_path + '/*/*.jpg')\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Returns the total number of samples'\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        'Generates one sample of data'\n",
    "        image_path = self.image_paths[idx]\n",
    "        \n",
    "        image = Image.open(image_path)\n",
    "        c = os.path.split(os.path.split(image_path)[0])[1]\n",
    "        y = self.name_to_label[c]\n",
    "        X = self.transform(image)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd27ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 128\n",
    "train_transform = transforms.Compose([transforms.Resize((size, size)), \n",
    "                                    transforms.ToTensor()])\n",
    "test_transform = transforms.Compose([transforms.Resize((size, size)), \n",
    "                                    transforms.ToTensor()])\n",
    "\n",
    "batch_size = 64\n",
    "trainset = Hotdog_NotHotdog(train=True, transform=train_transform)\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
    "testset = Hotdog_NotHotdog(train=False, transform=test_transform)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b898dac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "for i in range(21):\n",
    "    plt.subplot(5,7,i+1)\n",
    "    plt.imshow(np.swapaxes(np.swapaxes(images[i].numpy(), 0, 2), 0, 1))\n",
    "    plt.title(['hotdog', 'not hotdog'][labels[i].item()])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d422714",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.convolutional = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(),\n",
    "                nn.Conv2d(in_channels=8, out_channels=8, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(),\n",
    "                nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU())\n",
    "\n",
    "        self.fully_connected = nn.Sequential(\n",
    "                nn.Linear(64*64*16, 500),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(),\n",
    "                nn.Linear(500, 10),\n",
    "                nn.Softmax(dim=1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.convolutional(x)\n",
    "        #reshape x so it becomes flat, except for the first dimension (which is the minibatch)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fully_connected(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43e563d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define the training as a function so we can easily re-use it.\n",
    "def train(model, optimizer, num_epochs=10):\n",
    "    def loss_fun(output, target):\n",
    "        #return F.nll_loss(torch.log(output), target)\n",
    "        return F.binary_cross_entropy(output, target)\n",
    "    out_dict = {'train_acc': [],\n",
    "              'test_acc': [],\n",
    "              'train_loss': [],\n",
    "              'test_loss': []}\n",
    "    for epoch in tqdm(range(num_epochs), unit='epoch'):\n",
    "        model.train()\n",
    "        #For each epoch\n",
    "        train_correct = 0\n",
    "        train_loss = []\n",
    "        for minibatch_no, (data, target) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            target = target.to(torch.float32)\n",
    "            #print(len(target))\n",
    "            #Zero the gradients computed for each weight\n",
    "            optimizer.zero_grad()\n",
    "            #Forward pass your image through the network\n",
    "            #with torch.no_grad():\n",
    "            output = model(data)\n",
    "            \n",
    "            #Compute the loss\n",
    "            loss = loss_fun(output, target.reshape(-1,1))\n",
    "            #Backward pass through the network\n",
    "            loss.backward()\n",
    "            #Update the weights\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "            #Compute how many were correctly classified\n",
    "            predicted = torch.flatten(torch.where(output > 0.5, 1.0, 0.0))\n",
    "            train_correct += (target==predicted).sum().cpu().item()\n",
    "            #print(len(output))\n",
    "            #print(len(predicted))\n",
    "            #print(\"------------------\")\n",
    "            \n",
    "        #print(train_correct)\n",
    "        #Comput the test accuracy\n",
    "        test_loss = []\n",
    "        test_correct = 0\n",
    "        model.eval()\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            target = target.to(torch.float32)\n",
    "            with torch.no_grad():\n",
    "                output = model(data)\n",
    "            test_loss.append(loss_fun(output, target.reshape(-1,1)).cpu().item())\n",
    "            predicted = torch.flatten(torch.where(output > 0.5, 1.0, 0.0))\n",
    "            test_correct += (target==predicted).sum().cpu().item()\n",
    "            \n",
    "        out_dict['train_acc'].append(train_correct/len(train_set))\n",
    "        out_dict['test_acc'].append(test_correct/len(testset))\n",
    "        out_dict['train_loss'].append(np.mean(train_loss))\n",
    "        out_dict['test_loss'].append(np.mean(test_loss))\n",
    "        print(f\"Loss train: {np.mean(train_loss):.3f}\\t test: {np.mean(test_loss):.3f}\\t\",\n",
    "              f\"Accuracy train: {out_dict['train_acc'][-1]*100:.1f}%\\t test: {out_dict['test_acc'][-1]*100:.1f}%\")\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ef95d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network()\n",
    "model.to(device)\n",
    "#Initialize the optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.90)\n",
    "optimizer_adam = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1528b560",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict = train(model, optimizer_adam,num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3235a2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ebc812",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers=[x.data for x in model.parameters()]\n",
    "layers[0].cpu().detach().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbd6884",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,4)\n",
    "ax[0,0].imshow(layers[0].cpu().detach().numpy()[0][0],interpolation='none')\n",
    "ax[0,1].imshow(layers[0].cpu().detach().numpy()[1][0],interpolation='none')\n",
    "ax[0,2].imshow(layers[0].cpu().detach().numpy()[2][0],interpolation='none')\n",
    "ax[0,3].imshow(layers[0].cpu().detach().numpy()[3][0],interpolation='none')\n",
    "ax[1,0].imshow(layers[0].cpu().detach().numpy()[4][0],interpolation='none')\n",
    "ax[1,1].imshow(layers[0].cpu().detach().numpy()[5][0],interpolation='none')\n",
    "ax[1,2].imshow(layers[0].cpu().detach().numpy()[6][0],interpolation='none')\n",
    "ax[1,3].imshow(layers[0].cpu().detach().numpy()[7][0],interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acaa45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(10),np.array(out_dict[\"test_loss\"]),'-')\n",
    "plt.plot(np.arange(10),np.array(out_dict[\"train_loss\"]),'-')\n",
    "plt.legend(('Test error','Train eror'))\n",
    "plt.xlabel('Epoch number')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f3d369",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(10),np.array(out_dict[\"test_acc\"]),'-')\n",
    "plt.plot(np.arange(10),np.array(out_dict[\"train_acc\"]),'-')\n",
    "plt.legend(('Test error','Train eror'))\n",
    "plt.xlabel('Epoch number')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54551465",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_correct = 0\n",
    "targets = np.array([])\n",
    "predictions = np.array([])\n",
    "data_images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04864ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fun(output, target):\n",
    "    #return F.nll_loss(torch.log(output), target)\n",
    "    return F.binary_cross_entropy(output, target)\n",
    "test_loss = []\n",
    "test_correct = 0\n",
    "model.eval()\n",
    "i = 0\n",
    "for data, target in test_loader:\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    target = target.to(torch.float32)\n",
    "    with torch.no_grad():\n",
    "        output = model(data)\n",
    "    test_loss.append(loss_fun(output, target.reshape(-1,1)).cpu().item())\n",
    "    predicted = torch.flatten(torch.where(output > 0.5, 1.0, 0.0))\n",
    "    test_correct += (target==predicted).sum().cpu().item()\n",
    "    i += 1\n",
    "    targets = np.concatenate((targets,target.cpu().detach().numpy()))\n",
    "    predictions = np.concatenate((predictions,predicted.cpu().detach().numpy()))\n",
    "    #if i != 29:\n",
    "    data_images.append(data[:].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9c0942",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a101a903",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.swapaxes(np.swapaxes(images[i].numpy(), 0, 2), 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e16397",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_aspect(\"equal\")\n",
    "hist, xbins, ybins, im = ax.hist2d(targets, predictions,bins=[2,2])\n",
    "for i in range(len(ybins)-1):\n",
    "    for j in range(len(xbins)-1):\n",
    "        ax.text(xbins[j]+0.25,ybins[i]+0.25, hist.T[i,j], \n",
    "                color=\"w\", ha=\"center\", va=\"center\", fontweight=\"bold\")\n",
    "ax.set_ylabel('predictions')\n",
    "ax.set_xlabel('targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bc63c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6f2a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb03836e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2479f90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bdad07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386b0728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647c35f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23faac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9514f8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4142c3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e4b752",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = model_ft.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb138b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft.fc = nn.Linear(num_ftrs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bb95ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af68837",
   "metadata": {},
   "source": [
    "### Saliency map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c496cdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483e2cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pretrained resnet model\n",
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "#print(model)\n",
    "model.to(device)\n",
    "\n",
    "#define transforms to preprocess input image into format expected by model\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "#inverse transform to get normalize image back to original form for visualization\n",
    "inv_normalize = transforms.Normalize(\n",
    "    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.255],\n",
    "    std=[1/0.229, 1/0.224, 1/0.255]\n",
    ")\n",
    "\n",
    "#transforms to resize image to the size expected by pretrained model,\n",
    "#convert PIL image to tensor, and\n",
    "#normalize the image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    normalize,          \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72fc638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def saliency(img, model):\n",
    "    #we don't need gradients w.r.t. weights for a trained model\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    #set model in eval mode\n",
    "    model.eval()\n",
    "    #transoform input PIL image to torch.Tensor and normalize\n",
    "    input = transform(img)\n",
    "    input.unsqueeze_(0)\n",
    "\n",
    "    #we want to calculate gradient of higest score w.r.t. input\n",
    "    #so set requires_grad to True for input \n",
    "    input.requires_grad = True\n",
    "    #print(input)\n",
    "    #forward pass to calculate predictions\n",
    "    preds = model(input)\n",
    "    #print(preds)\n",
    "    score, indices = torch.max(preds, 1)\n",
    "    #backward pass to get gradients of score predicted class w.r.t. input image\n",
    "    score.backward()\n",
    "    #get max along channel axis\n",
    "    slc, _ = torch.max(torch.abs(input.grad[0]), dim=0)\n",
    "    #print(input.grad[0])\n",
    "    #normalize to [0..1]\n",
    "    slc = (slc - slc.min())/(slc.max()-slc.min())\n",
    "    #apply inverse transform on image\n",
    "    with torch.no_grad():\n",
    "        input_img = inv_normalize(input[0])\n",
    "    #plot image and its saleincy map\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(np.transpose(input_img.cpu().detach().numpy(), (1, 2, 0)))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(slc.cpu().detach().numpy(), cmap=plt.cm.hot)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "    return slc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb3c73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17882b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = images[36].to(device)\n",
    "slc = saliency(img, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea91ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "slc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
